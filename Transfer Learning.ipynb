{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from IPython.display import Image, display, clear_output\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "#from keras.regularizers import l2, activity_l2, l1, activity_l1\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg16(weights_path='C:/Users/hi/CarDent/car-damage-detective-master/vgg16.h5'):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(img_width, img_height,3)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "      \n",
    "    # assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\")'\n",
    "    \n",
    "    if weights_path:\n",
    "    # note: this chops off the last layers of VGG16 \n",
    "\n",
    "    # loads the weights of the VGG16 networks\n",
    "    # note: when there is a complete match between model definition\n",
    "    # and your weights savefile, you can simply call model.load_weights(filename)\n",
    "        f = h5py.File(weights_path)\n",
    "        for k in range(f.attrs['nb_layers']):\n",
    "            if k >= len(model.layers): \n",
    "                # we don't look at the last (fully-connected) layers in the savefile\n",
    "                break\n",
    "            g = f['layer_{}'.format(k)]\n",
    "            weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "            model.layers[k].set_weights(weights)\n",
    "        f.close()\n",
    "        print('VGG16 Model with partial weights loaded.')\n",
    "    else:\n",
    "        print('VGG16 Model with no weights Loaded.')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_16(weights_path='C:/Users/hi/CarDent/car-damage-detective-master/vgg16.h5'):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(img_width, img_height,3)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7c509eae5d01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights file\n",
    "location = 'C:/Users/hi/POC'\n",
    "top_model_weights_path=location+'/top_model_weights.h5' # will be saved into when we create our model\n",
    "# model_path = location + '/initial_data2_model.h5'\n",
    "fine_tuned_model_path = location+'/ft_model.h5'\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 256,256\n",
    "\n",
    "train_data_dir = 'D:/DS/Train_Images'\n",
    "validation_data_dir = 'D:/DS/Val_Images'\n",
    "\n",
    "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
    "nb_train_samples = sum(train_samples)\n",
    "validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
    "nb_validation_samples = sum(validation_samples)\n",
    "\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottleneck_features(location):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)  \n",
    "    \n",
    "    model = VGG_16()\n",
    "    \n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "    \n",
    "    generator = datagen.flow_from_directory(train_data_dir,\n",
    "                                            target_size=(img_width, img_height),\n",
    "                                            batch_size=5, \n",
    "                                            class_mode=None, \n",
    "                                            shuffle=False) \n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(generator, nb_train_samples)\n",
    "    np.save(open(location+'/bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "    \n",
    "    # repeat with the validation data\n",
    "    generator = datagen.flow_from_directory(validation_data_dir,\n",
    "                                           target_size=(img_width, img_height),\n",
    "                                           batch_size=3,\n",
    "                                           class_mode=None,\n",
    "                                           shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples)\n",
    "    np.save(open(location+'/bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 314 images belonging to 2 classes.\n",
      "Found 8 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bottleneck_features_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-0cafcdcb19ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/bottleneck_features_train.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottleneck_features_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bottleneck_features_train' is not defined"
     ]
    }
   ],
   "source": [
    "np.save(open(location+'/bottleneck_features_train.npy', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(hist, stop=50):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
    "                            \n",
    "    axes = axes.flatten()\n",
    "\n",
    "    axes[0].plot(range(stop), hist['acc'], label='Training', color='#FF533D')\n",
    "    axes[0].plot(range(stop), hist['val_acc'], label='Validation', color='#03507E')\n",
    "    axes[0].set_title('Accuracy')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].legend(loc='lower right')\n",
    "                             \n",
    "    axes[1].plot(range(stop), hist['loss'], label='Training', color='#FF533D')\n",
    "    axes[1].plot(range(stop), hist['val_loss'], label='Validation', color='#03507E')\n",
    "    axes[1].set_title('Loss')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].legend(loc='upper right')\n",
    "                             \n",
    "    plt.tight_layout();\n",
    "    \n",
    "    print (\"Best Model:\" )\n",
    "    print_best_model_results(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open('C:/Users/hi/POC/bottleneck_features_train.npy',\"rb\"))\n",
    "validation_data = np.load(open(location+'/bottleneck_features_validation.npy',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566, 8, 8, 512)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " validation_labels = np.array([0] * validation_samples[0] + \n",
    "                                 [1] * validation_samples[1])\n",
    "validation_labels\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_model():\n",
    "\n",
    "    train_data = np.load(open('C:/Users/hi/POC/bottleneck_features_train.npy',\"rb\"))\n",
    "    train_labels = np.array([0] * train_samples[0] + \n",
    "                            [1] * train_samples[1])\n",
    "\n",
    "    validation_data = np.load(open(location+'/bottleneck_features_validation.npy',\"rb\"))\n",
    "    validation_labels = np.array([0] * validation_samples[0] + \n",
    "                                 [1] * validation_samples[1])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:])) # 512, 4, 4\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(1, activation = 'sigmoid')) # should activation be sigmoid for binary problem?\n",
    "\n",
    "    model.compile(optimizers.SGD(lr=0.0001, momentum=0.9),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #checkpoint = ModelCheckpoint(top_model_weights_path, monitor='val_acc',verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
    "\n",
    "    fit = model.fit(train_data, train_labels,\n",
    "              nb_epoch=nb_epoch, batch_size=16,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    \n",
    "    with open(location+'/top_history.txt', 'wb') as f:\n",
    "        json.dump(fit.history, f)\n",
    "    \n",
    "    return model, fit.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 1566 input samples and 314 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-7a959cdb343a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md1a_model2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md1a_history2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_binary_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-b9036bec5ba7>\u001b[0m in \u001b[0;36mtrain_binary_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     fit = model.fit(train_data, train_labels,\n\u001b[0;32m     24\u001b[0m               \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m               validation_data=(validation_data, validation_labels))\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/top_history.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    956\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    805\u001b[0m             ]\n\u001b[0;32m    806\u001b[0m             \u001b[1;31m# Check that all arrays have the same length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[1;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[1;34m(inputs, targets, weights)\u001b[0m\n\u001b[0;32m    233\u001b[0m                          \u001b[1;34m'the same number of samples as target arrays. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                          \u001b[1;34m'Found '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' input samples '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[1;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 1566 input samples and 314 target samples."
     ]
    }
   ],
   "source": [
    "d1a_model2, d1a_history2 = train_binary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " def finetune_binary_model():\n",
    "    model = load_vgg16()\n",
    "\n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu', W_regularizer=l2(0.01)))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    top_model.load_weights(top_model_weights_path) # load weights_path\n",
    "\n",
    "    # add the model on top of the convolutional base\n",
    "    model.add(top_model)\n",
    "    \n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable - weights will not be updated\n",
    "    for layer in model.layers[:25]:\n",
    "        layer.trainable=False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer \n",
    "    # and a very slow learning rate\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer = optimizers.SGD(lr=0.00001, momentum=0.9), # reduced learning rate by 1/10\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                       rotation_range=40,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode='nearest')\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator= train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                     target_size=(img_height, img_width),\n",
    "                                                     batch_size=8,\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                           target_size=(img_height, img_width),\n",
    "                                                           batch_size=8,\n",
    "                                                           class_mode='binary')\n",
    "    \n",
    "    \n",
    "    checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_acc', \n",
    "                                 verbose=1, save_best_only=True, \n",
    "                                 save_weights_only=False, mode='auto')\n",
    "    # fine-tune the model\n",
    "    fit = model.fit_generator(train_generator,\n",
    "                              samples_per_epoch=nb_train_samples,\n",
    "                              nb_epoch=nb_epoch,\n",
    "                              validation_data=validation_generator,\n",
    "                              nb_val_samples=nb_validation_samples,\n",
    "                              verbose=1,\n",
    "                              callbacks=[checkpoint])\n",
    "    \n",
    "    with open(location+'/ft_history.txt', 'wb') as f:\n",
    "        json.dump(fit.history, f)\n",
    "    \n",
    "    return model, fit.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights file\n",
    "location = 'C:/Users/hi/POC'\n",
    "top_model_weights_path=location+'/top_model_weights.h5' # will be saved into when we create our model\n",
    "# model_path = location + '/initial_data2_model.h5'\n",
    "fine_tuned_model_path = location+'/ft_model.h5'\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "train_data_dir = 'D:/DS/Train_Images'\n",
    "validation_data_dir = 'D:/DS/Val_Images'\n",
    "\n",
    "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n",
    "nb_train_samples = sum(train_samples)\n",
    "validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]\n",
    "nb_validation_samples = sum(validation_samples)\n",
    "\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_model(model, directory, labels):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                target_size=(img_height, img_width),\n",
    "                                batch_size=8,\n",
    "                                class_mode='binary', # categorical for multiclass\n",
    "                                shuffle=False)\n",
    "    \n",
    "    predictions = model.predict_generator(generator, len(labels))\n",
    "    \n",
    "    # use for multiclass\n",
    "    # pred_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    pred_labels = [0 if i <0.5 else 1 for i in predictions]\n",
    "\n",
    "   \n",
    "    print (classification_report(validation_labels, pred_labels))\n",
    "    \n",
    "    cm = confusion_matrix(validation_labels, pred_labels)\n",
    "    sns.heatmap(cm, annot=True, fmt='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\hi\\\\Desktop\\\\Images1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a2a33d8ec0e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# the .flow() command below generates batches of randomly transformed images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# and saves the results to the 'preview/' directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\hi\\\\Desktop\\\\Images1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m for batch in datagen.flow(x, batch_size=1,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\hi\\\\Desktop\\\\Images1'"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest') # omitted rescaling to keep the images displayable\n",
    "\n",
    "img = load_img('C:\\\\Users\\\\hi\\\\Desktop\\\\CarImages3.JPG') # this is a PIL image \n",
    "x = img_to_array(img) # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape) # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the 'preview/' directory\n",
    "os.makedirs('C:\\\\Users\\\\hi\\\\Desktop\\\\Images1')\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                         save_to_dir='Images1', save_prefix='damage_car',\n",
    "                         save_format='jpeg'):\n",
    "    i +=1\n",
    "    if i > 5:\n",
    "        break # otherwise the generator would loop indefinitely\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the model weights file\n",
    "location = 'D:/DS'\n",
    "#top_model_weights_path=location+'/top_model_weights.h5' # will be saved into when we create our model\n",
    "# model_path = location + '/initial_data2_model.h5'\n",
    "#fine_tuned_model_path = location+'/ft_model.h5'\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "train_data_dir = location+'/POC_Images'\n",
    "validation_data_dir = location+'/Val_Images'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/DS/POC_Images'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 214]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
